{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.datasets import load_digits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class plots the relevant raster plot of spikes and validation accuracy over time\n",
    "\n",
    "class Spike_Plotter:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "     \n",
    "    # Raster plot of spiking behavior for input and output neurons\n",
    "    def Raster_Plot(self,title,input_data,output_data):\n",
    "        \n",
    "        def Convert_Data_To_Raster(data):\n",
    "            result = []\n",
    "            for i in range(len(data)):\n",
    "                result.append([])\n",
    "                for j in range(len(data[i])):\n",
    "                    to_add = data[i][j]*j\n",
    "                    if to_add!=0:\n",
    "                        result[i].append(to_add)\n",
    "            return result\n",
    "        \n",
    "        # Set different colors for each neuron\n",
    "        colorCodes = np.array([[0, 0, 0], [1, 0, 0], [0, 1, 0]])\n",
    "\n",
    "        # Set spike colors for each neuron\n",
    "        lineSize = [0.5, 0.5, 0.5]                                  \n",
    "\n",
    "        # Draw a spike raster plot\n",
    "        preparedData = input_data\n",
    "        preparedData.append(np.array(output_data))\n",
    "        neuralData = Convert_Data_To_Raster(preparedData)\n",
    "        \n",
    "        plt.yticks([0,1,2],['Input x','Input y','Output z'])\n",
    "        plt.eventplot(neuralData, color=colorCodes, linelengths=lineSize)     \n",
    "\n",
    "        plt.title('Spike Raster Plot '+title)\n",
    "        plt.ylabel('Neuron')\n",
    "        plt.xlabel('Time (msecs)')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    # Plots validation accuracy over time\n",
    "    def Validation_Plot(self, accuracies):\n",
    "        plt.title('Validation Data Accuracy Per Training Iteration')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Training Iteration')\n",
    "        plt.plot(range(len(accuracies)), accuracies)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Neuron Class manages all the parameters and models that are used for testing.  \n",
    "# The class requires the models are first initialized by giving the model parameters before running\n",
    "# Then the proper model's membrane potential function can be called for a given input current\n",
    "# The returned voltage and spiking behavior across the duration of the current will be returned\n",
    "\n",
    "#POTENTIAL_DECAY = 0.8\n",
    "#CURRENT_DECAY = 0.8\n",
    "\n",
    "#class Neuron:\n",
    "#    def __init__(self):\n",
    "#        self.LIF_initialilzed = False\n",
    "\n",
    "#    def Initialize_LIF(self,neuron_resting_voltage,neuron_firing_threshold,C_m, R_m):\n",
    "#        self.C_m = C_m\n",
    "#        self.R_m = R_m\n",
    "#        self.resting_voltage=neuron_resting_voltage\n",
    "#        self.voltage_threshold=neuron_firing_threshold\n",
    "#        self.LIF_initialized = True\n",
    "        \n",
    "#    def LIF_Neuron_Voltage_Current_Change(self,t,I, V_m, spike_trains, trained_weights,spike_occurrence_array):\n",
    "#        if self.LIF_initialized:\n",
    "#            I[t] = CURRENT_DECAY*I[t-1] + np.sum(spike_trains[:,t]*trained_weights)\n",
    "#            if V_m[t-1] < self.voltage_threshold:\n",
    "#                V_m[t] = POTENTIAL_DECAY*V_m[t-1] + I[t]\n",
    "#                spike_occurrence_array[t-1] = 0\n",
    "#            else:\n",
    "#                V_m[t] = self.resting_voltage\n",
    "#                spike_occurrence_array[t-1] = 1\n",
    "#\n",
    "#            return I, V_m\n",
    "#        else:\n",
    "#            raise Exception('LIF was not initialized')\n",
    "#        \n",
    "#    def LIF_Membrane_Potential(self,time, spike_trains, trained_weights):\n",
    "#\n",
    "#        spike_occurrence_array = np.zeros(time)\n",
    "#        current_voltage = self.resting_voltage\n",
    "#        V_m = np.zeros(time)\n",
    "#        input_current = np.zeros(time)\n",
    "#        for t in range(1,time):\n",
    "#            input_current,V_m = self.LIF_Neuron_Voltage_Current_Change(t,input_current, \\\n",
    "#                                       V_m,spike_trains, trained_weights,spike_occurrence_array)\n",
    "#\n",
    "#        return input_current, V_m,spike_occurrence_array\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy version\n",
    "# A simplified Leaky-Integrate-And-Fire Neuron designed for STDP\n",
    "# Each neuron keeps track of the parameters used in the SNN construction so that they can be referred to\n",
    "# The neuron tracks each of its fired spikes and the time between firings.\n",
    "# The neuron also holds references to its presynaptic neurons and the weights of those connections\n",
    "\n",
    "class Simplified_Neuron:\n",
    "    def __init__(self,layer_number,parameters):\n",
    "        self.parameters = parameters\n",
    "        self.layer_number=layer_number\n",
    "        \n",
    "        self.t = 0\n",
    "        self.spike_fired=[]\n",
    "        self.time_since_spike=0\n",
    "        \n",
    "        self.preset_spikes = False\n",
    "        \n",
    "        self.current_potential = self.parameters.resting_potential\n",
    "        self.presynaptic_neurons = None\n",
    "        self.weights = None\n",
    "        \n",
    "    # Updates the membrane potential of the neuron at each time step based on the incoming spikes of the presynaptic neurons\n",
    "\n",
    "    def Update_Membrane_Potential(self):\n",
    "        if not self.preset_spikes:\n",
    "            spike_fired=0\n",
    "            new_potential = self.parameters.resting_potential\n",
    "            if self.parameters.minimum_potential<self.current_potential and self.current_potential < self.parameters.threshold_potential:\n",
    "                incoming_spikes = self.Check_Presynaptic_Spikes()\n",
    "                new_potential = self.current_potential+np.sum(incoming_spikes*self.weights)-self.parameters.delay\n",
    "            elif self.parameters.threshold_potential <= self.current_potential:\n",
    "                spike_fired=1\n",
    "                new_potential = self.parameters.resting_potential\n",
    "            elif self.current_potential <= self.parameters.minimum_potential:\n",
    "                new_potential = self.parameters.resting_potential\n",
    "            self.current_potential = new_potential\n",
    "            self.spike_fired.append(spike_fired)\n",
    "        if self.spike_fired[self.t]==1:\n",
    "            self.time_since_spike=0\n",
    "        else:    \n",
    "            self.time_since_spike=self.time_since_spike+1\n",
    "        self.t+=1\n",
    "    \n",
    "    # Obtains the calculations for updating the weights and updates all the weights to the presynaptic neurons\n",
    "    \n",
    "    \n",
    "    def Input_Spikes(self,spike_train):\n",
    "        self.spike_fired = spike_train\n",
    "        self.preset_spikes = True\n",
    "        \n",
    "    # Resets the membrane potential of the neuron\n",
    "        \n",
    "    def Reset_T(self):\n",
    "        self.t = 0\n",
    "        \n",
    "    # Resets the neuron to default after using the training spike information\n",
    "    def Clear_Neuron(self):\n",
    "        self.Reset_T()\n",
    "        self.spike_fired = []\n",
    "        self.time_since_spike = 0\n",
    "        self.current_potential = self.parameters.resting_potential\n",
    "        self.preset_spikes = False\n",
    "    \n",
    "    # Determines if the presynaptic neurons have spiked\n",
    "    def Check_Presynaptic_Spikes(self):\n",
    "        spikes = []\n",
    "        for neuron in self.presynaptic_neurons:\n",
    "            spikes.append(neuron.Get_Spike())\n",
    "        return np.array(spikes)\n",
    "    \n",
    "    # Returns if the array of all neuron spikes up to the current time\n",
    "    def Get_All_Spikes(self):\n",
    "        return self.spike_fired\n",
    "    \n",
    "    def Get_Spike(self):\n",
    "        return self.spike_fired[self.t-1]\n",
    "    \n",
    "    # Checks how long it has been since the neuron has spiked\n",
    "    def Get_Time_Since_Spike(self):\n",
    "        return self.time_since_spike\n",
    "    \n",
    "    # Updates the references to all the presynaptic layer neurons and generates initial weights\n",
    "    def Set_Presynaptic_Neurons(self,presynaptic_neurons):\n",
    "        self.presynaptic_neurons = presynaptic_neurons\n",
    "        weights = []\n",
    "        \n",
    "        initial_weights=np.random.uniform(self.parameters.w_min,self.parameters.w_max,len(presynaptic_neurons))\n",
    "        for i in range(len(presynaptic_neurons)):\n",
    "            #weights.append(initial_weights[i])\n",
    "            weights.append(0.5)\n",
    "        self.weights = np.array(weights)\n",
    "    \n",
    "    # Recursive propagation through the layers of the network updating the weights\n",
    "    def Recursive_Weight_Updates(self):\n",
    "        if self.presynaptic_neurons is not None:\n",
    "            for i in range(len(self.presynaptic_neurons)):\n",
    "                neuron = self.presynaptic_neurons[i]\n",
    "                neuron.Recursive_Weight_Updates()\n",
    "                self.weights[i]=self.New_Weight(neuron,self.weights[i])\n",
    "    \n",
    "    # Recursive propagation through the layers of the network updating each neurons spiking potential\n",
    "    def Recursive_Spike_Propagation(self):\n",
    "        if self.presynaptic_neurons is not None:\n",
    "            for i in range(len(self.presynaptic_neurons)):\n",
    "                neuron = self.presynaptic_neurons[i]\n",
    "                neuron.Recursive_Spike_Propagation()\n",
    "        self.Update_Membrane_Potential()\n",
    "        \n",
    "    # Gets the time difference between the latest post-synaptic and pre-synaptic spike\n",
    "    def Get_Delta_T(self,presynaptic_neuron):\n",
    "        if presynaptic_neuron.Get_Spike()==1 or self.Get_Spike()==1:\n",
    "            presynaptic_t = presynaptic_neuron.Get_Time_Since_Spike()\n",
    "            self_t = self.Get_Time_Since_Spike()\n",
    "            delta_t= presynaptic_t - self_t\n",
    "        else:\n",
    "            delta_t=0\n",
    "        return delta_t\n",
    "        \n",
    "    # Determines the change in the weight based on the time difference between spikes\n",
    "    def Get_Delta_Weight(self,presynaptic_neuron):\n",
    "        delta_t=self.Get_Delta_T(presynaptic_neuron)\n",
    "        delta_weight=0\n",
    "        if delta_t<=-2:\n",
    "            delta_weight=self.parameters.A_minus*np.exp(delta_t/self.parameters.tau_minus)\n",
    "        elif delta_t>=2:\n",
    "            delta_weight=self.parameters.A_plus*np.exp(delta_t/self.parameters.tau_plus)\n",
    "        return delta_weight\n",
    "    \n",
    "    # Determines the new weight value of each synaptic connection\n",
    "    def New_Weight(self,presynaptic_neuron,old_weight):\n",
    "        delta_weight=self.Get_Delta_Weight(presynaptic_neuron)\n",
    "        new_weight=old_weight\n",
    "        \n",
    "        if delta_weight>0:\n",
    "            new_weight = old_weight + self.parameters.learning_rate*delta_weight*(self.parameters.w_max-old_weight)\n",
    "        elif delta_weight<=0:\n",
    "            new_weight = old_weight + self.parameters.learning_rate*delta_weight*(old_weight-self.parameters.w_min)\n",
    "        \n",
    "        if new_weight>self.parameters.w_max:\n",
    "            new_weight=self.parameters.w_max\n",
    "        if new_weight<self.parameters.w_min:\n",
    "            new_weight=self.parameters.w_min\n",
    "        \n",
    "        return new_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class holds onto all the relevant parameter information of the Spiking Neural Network\n",
    "# so that it can be referenced by other classes\n",
    "\n",
    "class Network_Parameters:\n",
    "     def __init__(self,learning_rate,minimum_potential,threshold_potential,resting_potential,delay,A_minus,A_plus,tau_minus,tau_plus,w_max,w_min):\n",
    "        self.threshold_potential = threshold_potential\n",
    "        self.resting_potential = resting_potential\n",
    "        self.minimum_potential = minimum_potential\n",
    "        self.delay = delay\n",
    "        self.learning_rate = learning_rate\n",
    "        self.A_minus=A_minus\n",
    "        self.A_plus=A_plus\n",
    "        self.tau_minus=tau_minus\n",
    "        self.tau_plus=tau_plus\n",
    "        self.w_max = w_max\n",
    "        self.w_min = w_min\n",
    "        if w_min>w_max:\n",
    "            print(\"Weight min/max error\")\n",
    "        \n",
    "# The STDP Spiking Neural Network that holds the neuron layers\n",
    "# The class initiates updates to weights and membrane potentials\n",
    "\n",
    "class Spiking_Neural_Network:\n",
    "    def __init__(self,num_of_input_neurons,parameters):\n",
    "        self.parameters=parameters\n",
    "        self.input_neurons = []\n",
    "        self.output_neurons = []\n",
    "        for i in range(num_of_input_neurons):\n",
    "            neuron=Simplified_Neuron(1,self.parameters)\n",
    "            self.input_neurons.append(neuron)\n",
    "            self.output_neurons.append(neuron)\n",
    "        self.num_of_layers = 1\n",
    "        \n",
    "    # Adds a new layer of neurons to the network and makes that layer the new output layer\n",
    "    def Add_New_Layer(self,num_of_neurons):\n",
    "        self.num_of_layers+=1\n",
    "        new_output_neurons = []\n",
    "        for i in range(num_of_neurons):\n",
    "            neuron=Simplified_Neuron(self.num_of_layers,self.parameters)\n",
    "            neuron.Set_Presynaptic_Neurons(self.output_neurons)\n",
    "            new_output_neurons.append(neuron)\n",
    "        self.output_neurons=new_output_neurons\n",
    "        \n",
    "    # Recursively moves through the layers updating all the weights\n",
    "    def Update_Network_Weights(self):\n",
    "        for neuron in self.output_neurons:\n",
    "            neuron.Recursive_Weight_Updates()\n",
    "            \n",
    "    # Recursively moves through the layers updating all the spiking potentials\n",
    "    def Update_Membrane_Potential(self):\n",
    "        for neuron in self.output_neurons:\n",
    "            neuron.Recursive_Spike_Propagation()\n",
    "            \n",
    "# A network manager that holds onto the SNN as well as it's relevant parameters\n",
    "# Manages the training and testing of the network itself\n",
    "\n",
    "class Spiking_Neural_Network_Manager:\n",
    "    def __init__(self):\n",
    "        self.parameters_established = False\n",
    "        self.network_established = False\n",
    "    \n",
    "    def Establish_Parameters(self,learning_rate,minimum_potential,threshold_potential,resting_potential,delay,A_minus,A_plus,tau_minus,tau_plus,w_max,w_min):\n",
    "        self.parameters = Network_Parameters(learning_rate,minimum_potential,threshold_potential,resting_potential,delay,A_minus,A_plus,tau_minus,tau_plus,w_max,w_min)\n",
    "        self.parameters_established = True\n",
    "        \n",
    "    def Establish_Network(self,num_of_inputs):\n",
    "        if self.parameters_established:\n",
    "            self.network=Spiking_Neural_Network(num_of_inputs,self.parameters)\n",
    "            self.network_established = True\n",
    "            \n",
    "    def Add_New_Layer(self,num_of_neurons):\n",
    "        if self.network_established:\n",
    "            self.network.Add_New_Layer(num_of_neurons)\n",
    "            \n",
    "    # Sets all the input and output neurons to use preset input spikes for training\n",
    "    def Prepare_To_Train(self,x,y):\n",
    "        for i in range(len(self.network.input_neurons)):\n",
    "            self.network.input_neurons[i].Input_Spikes(x[i])\n",
    "            #print(self.network.input_neurons[i].spike_fired)\n",
    "        for i in range(len(self.network.output_neurons)):\n",
    "            self.network.output_neurons[i].Input_Spikes(y[i])\n",
    "            \n",
    "    # Resets the neurons to initial time state\n",
    "    def Reset_T(self):\n",
    "        for neuron in self.network.input_neurons:\n",
    "            neuron.Reset_T()\n",
    "        for neuron in self.network.output_neurons:\n",
    "            neuron.Reset_T()\n",
    "        \n",
    "    # Completely resets the neuron to default\n",
    "    def Clear_Neurons(self):\n",
    "        for neuron in self.network.input_neurons:\n",
    "            neuron.Clear_Neuron()\n",
    "        for neuron in self.network.output_neurons:\n",
    "            neuron.Clear_Neuron()\n",
    "    \n",
    "    # Sets all the input neurons to use preset input spikes for testing\n",
    "    def Prepare_To_Test(self,x):\n",
    "        for i in range(len(self.network.input_neurons)):\n",
    "            self.network.input_neurons[i].Input_Spikes(x[i])\n",
    "    \n",
    "    # Trains the network using the preset input data x and output data y\n",
    "    def Train(self,x,y):\n",
    "        if self.network_established:\n",
    "            self.Prepare_To_Train(x,y)\n",
    "            \n",
    "            for i in range(len(x[0])):\n",
    "                self.network.Update_Membrane_Potential()\n",
    "                self.network.Update_Network_Weights()\n",
    "                \n",
    "            self.Clear_Neurons()\n",
    "    \n",
    "    # Trains the network using the preset input data x and output data y\n",
    "    # After each training iteration, tests the network on the validation data and records the accuracy\n",
    "    \n",
    "\n",
    "                \n",
    "    # Tests the network on the preset input data x and records the output\n",
    "    def Test(self,x):\n",
    "\n",
    "        if self.network_established:\n",
    "            self.Prepare_To_Test(x)\n",
    "            \n",
    "            for i in range(len(x[0])):\n",
    "                self.network.Update_Membrane_Potential()\n",
    "            \n",
    "            result=[]\n",
    "            for neuron in self.network.output_neurons:\n",
    "                result.append(neuron.Get_All_Spikes())\n",
    "            \n",
    "            self.Clear_Neurons()    \n",
    "            return result\n",
    "               \n",
    "    def Validation_Train(self,number_of_training_iterations,x,y,validation_x):\n",
    "        if self.network_established:\n",
    "            results = []\n",
    "            for i in range(number_of_training_iterations):\n",
    "                self.Train(x,y)\n",
    "                validation_y=self.Test(validation_x)\n",
    "                results.append(validation_y)\n",
    "            \n",
    "            return results\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manages the encoding and decoding of the data into spike trains that can be input into the network\n",
    "# Records a goal spiking rate per second and how many milliseconds to generate data for\n",
    "class Data:\n",
    "    def __init__(self,dt,nbins):\n",
    "        self.dt = float(dt)/1000\n",
    "        self.nbins=nbins\n",
    "\n",
    "    \n",
    "    # Generate A Poisson Spike Train\n",
    "    def __Encode(self,firing_rate):\n",
    "        spike_rate = float(firing_rate*self.dt)\n",
    "        spike_trains = np.random.binomial(size=self.nbins,n=1,p=spike_rate)\n",
    "        return spike_trains\n",
    "    \n",
    "    # Decodes the firing rate of given Spike Train\n",
    "    def __Decode(self,spike_train):\n",
    "        nbins = len(spike_train)\n",
    "        spike_count = np.sum(spike_train) \n",
    "        spike_rate = float(spike_count)/ nbins\n",
    "        firing_rate = float(spike_rate) / self.dt\n",
    "        return firing_rate\n",
    "    \n",
    "    # Encodes a binary bit into a spike train depending on which bit is input\n",
    "    def Boolean_Encode(self,bit):\n",
    "        firing_rate_1 = 50\n",
    "        firing_rate_0 = 10\n",
    "        if bit==1:\n",
    "            firing_rate = firing_rate_1\n",
    "        elif bit==0:\n",
    "            firing_rate = firing_rate_0\n",
    "        else:\n",
    "            raise Exception(\"Did not input a 1/0 bit\")\n",
    "        spike_train=self.__Encode(firing_rate)\n",
    "        return spike_train\n",
    "        \n",
    "    def Boolean_Decode(self,spike_train):\n",
    "        firing_rate = self.__Decode(spike_train)\n",
    "        return firing_rate\n",
    "        \n",
    "    def Standard_Encode(self,value):\n",
    "        multiplier = 1\n",
    "        firing_rate = value\n",
    "        spike_train=self.__Encode(firing_rate*multiplier)\n",
    "        return spike_train\n",
    "    \n",
    "    def __Randomize_Order(self,length):\n",
    "        array = np.arange(length)\n",
    "        np.random.shuffle(array)\n",
    "        return array\n",
    "        \n",
    "    \n",
    "    # Generates spike trains for boolean logic gate inputs 1-1,1-0,0-1,0-0 in a randomized order\n",
    "    def __Gate_Random_Samples_Values(self,random_order):\n",
    "        x_sample = [self.Boolean_Encode(1),self.Boolean_Encode(1),self.Boolean_Encode(0),self.Boolean_Encode(0)]\n",
    "        y_sample = [self.Boolean_Encode(1),self.Boolean_Encode(0),self.Boolean_Encode(1),self.Boolean_Encode(0)]\n",
    "        \n",
    "        x = np.concatenate((x_sample[random_order[0]],x_sample[random_order[1]],x_sample[random_order[2]],x_sample[random_order[3]]))\n",
    "        y = np.concatenate((y_sample[random_order[0]],y_sample[random_order[1]],y_sample[random_order[2]],y_sample[random_order[3]]))\n",
    "\n",
    "        return x,y\n",
    "        \n",
    "        \n",
    "    # Generates the spike trains of input and output of a boolean 'AND' gate\n",
    "    def __AND_Gate(self):\n",
    "        random_order=self.__Randomize_Order(4)\n",
    "\n",
    "        x,y=self.__Gate_Random_Samples_Values(random_order)\n",
    "                    \n",
    "        z_sample = [self.Boolean_Encode(1),self.Boolean_Encode(0),self.Boolean_Encode(0),self.Boolean_Encode(0)]   \n",
    "        z = np.concatenate((z_sample[random_order[0]],z_sample[random_order[1]],z_sample[random_order[2]],z_sample[random_order[3]]))\n",
    "        \n",
    "        return x,y,z\n",
    "        \n",
    "    # Generates the spike trains of input and output of a boolean 'OR' gate\n",
    "    def __OR_Gate(self):\n",
    "        random_order=self.__Randomize_Order(4)\n",
    "\n",
    "        x,y=self.__Gate_Random_Samples_Values(random_order)\n",
    "                    \n",
    "        z_sample = [self.Boolean_Encode(1),self.Boolean_Encode(1),self.Boolean_Encode(1),self.Boolean_Encode(0)]   \n",
    "        z = np.concatenate((z_sample[random_order[0]],z_sample[random_order[1]],z_sample[random_order[2]],z_sample[random_order[3]]))\n",
    "        \n",
    "        return x,y,z\n",
    "\n",
    "    # Generates the spike trains of input and output of a boolean 'XOR' gate\n",
    "    def __XOR_Gate(self):\n",
    "        random_order=self.__Randomize_Order(4)\n",
    "\n",
    "        x,y=self.__Gate_Random_Samples_Values(random_order)\n",
    "                    \n",
    "        z_sample = [self.Boolean_Encode(0),self.Boolean_Encode(1),self.Boolean_Encode(1),self.Boolean_Encode(0)]   \n",
    "        z = np.concatenate((z_sample[random_order[0]],z_sample[random_order[1]],z_sample[random_order[2]],z_sample[random_order[3]]))\n",
    "        \n",
    "        return x,y,z\n",
    "\n",
    "                    \n",
    "    # Switch for determining which data to generate and how many times to perform a draw\n",
    "    def Generate_Gate_Data(self,gate,num_of_draws):\n",
    "                    \n",
    "        for i in range(num_of_draws):\n",
    "            if gate=='AND':\n",
    "                x_sec,y_sec,z_sec=self.__AND_Gate()\n",
    "            elif gate=='OR':\n",
    "                x_sec,y_sec,z_sec=self.__OR_Gate()\n",
    "            elif gate=='XOR':\n",
    "                x_sec,y_sec,z_sec=self.__XOR_Gate()\n",
    "\n",
    "            if i==0:\n",
    "                x = x_sec\n",
    "                y = y_sec\n",
    "                z = z_sec\n",
    "            else:\n",
    "                x = np.concatenate((x,x_sec))\n",
    "                y = np.concatenate((y,y_sec))\n",
    "                z = np.concatenate((z,z_sec))\n",
    "            \n",
    "        return x,y,z\n",
    "    \n",
    "    def Generate_Gate_Test_Data(self):\n",
    "        x_1_1=self.Boolean_Encode(1)\n",
    "        y_1_1=self.Boolean_Encode(1)\n",
    "                    \n",
    "        x_1_0=self.Boolean_Encode(1)\n",
    "        y_1_0=self.Boolean_Encode(0)\n",
    "                    \n",
    "        x_0_1=self.Boolean_Encode(0)\n",
    "        y_0_1=self.Boolean_Encode(1)\n",
    "                    \n",
    "        x_0_0=self.Boolean_Encode(0)\n",
    "        y_0_0=self.Boolean_Encode(0)\n",
    "                    \n",
    "        return (x_1_1,y_1_1), (x_1_0,y_1_0), (x_0_1, y_0_1), (x_0_0, y_0_0)\n",
    "                    \n",
    "# Generates the digit class data\n",
    "class Digit_Data:\n",
    "    def __init__(self,dt,nbins):\n",
    "        self.train_ratio = 0.75\n",
    "        self.validation_ratio = 0.15\n",
    "        self.test_ratio = 0.10\n",
    "        self.threshold_intensity = 0.035\n",
    "        self.data = Data(dt,nbins)\n",
    "    \n",
    "    # Obtains the dataset and splits into train, validation and test sets\n",
    "    def __Obtain_MNIST_Data(self,option):\n",
    "        digits,values  = load_digits()['images'],load_digits()['target']\n",
    "        new_digits = []\n",
    "        new_values = []\n",
    "        possible_outputs = []\n",
    "        if option==\"1-8\":\n",
    "            for i in range(len(values)):\n",
    "                if values[i]==1 or values[i]==8:\n",
    "                    new_digits.append(digits[i])\n",
    "                    new_values.append(values[i])\n",
    "            possible_outputs = [1,8]\n",
    "        elif option==\"3-8\":\n",
    "            for i in range(len(values)):\n",
    "                if values[i]==3 or values[i]==8:\n",
    "                    new_digits.append(digits[i])\n",
    "                    new_values.append(values[i])\n",
    "            possible_outputs = [3,8]\n",
    "        elif option=='ALL':\n",
    "            new_digits=digits\n",
    "            new_values=values\n",
    "            possible_outputs = [0,1,2,3,4,5,6,7,8,9]\n",
    "        else:\n",
    "            raise Exception(\"No dataset selected\")\n",
    "        return possible_outputs,new_digits,new_values\n",
    "        \n",
    "    def __Train_Test_Split(self,data,values):\n",
    "        train_data,test_data,train_values,test_values = train_test_split(data,values,test_size=1-self.train_ratio)\n",
    "        test_data,validation_data,test_values,validation_values = \\\n",
    "                        train_test_split(test_data,test_values, test_size = self.test_ratio/(self.test_ratio+self.validation_ratio))\n",
    "        return (train_data,train_values), (test_data,test_values), (validation_data,validation_values)\n",
    "                    \n",
    "    def __Encode_Sample(self,data_array):\n",
    "        encoded_sample=[]\n",
    "        for i in range(len(data_array)):\n",
    "            sample_row = []\n",
    "            for j in range(len(data_array[i])):\n",
    "                sample_spike_train=self.data.Standard_Encode(data_array[i][j])\n",
    "                sample_row.append(sample_spike_train)\n",
    "            samples.append(sample_row)\n",
    "        encoded_sample\n",
    "    \n",
    "    def __Encode_All_Samples(self,data_array,values_array,possible_values):\n",
    "        encoded_inputs = []\n",
    "        encoded_outputs = []\n",
    "        for i in range(len(data_array)):\n",
    "            encoded_pixels=self.Encode_Sample(data_array[i])\n",
    "            encoded_inputs.append(encoded_pixels)\n",
    "            output_sample=self.__Encode_Digit_Output(values_array[i],possible_values)\n",
    "            encoded_outputs.append(output_sample)\n",
    "        return encoded_inputs,encoded_outputs\n",
    "    \n",
    "    def __Concatenate_For_Training(self,data_spikes,value_spikes):\n",
    "        encoded_inputs = []\n",
    "        encoded_outputs = []\n",
    "        for j in range(len(data_array[0])):\n",
    "            encoded_input_row = []\n",
    "            for k in range(len(data_array[0][j])):\n",
    "                    encoded_input_row.append([])\n",
    "            encoded_inputs.append(encoded_input_row)\n",
    "                    \n",
    "        for j in range(len(value_spikes[0])):\n",
    "            encoded_outputs.append([])\n",
    "        \n",
    "                    \n",
    "        for i in range(len(data_spikes)):\n",
    "            for j in range(len(data_spikes[i])):\n",
    "                for k in range(len(data_spikes[j][k])):\n",
    "                    if i==0:\n",
    "                        encoded_inputs[j][k].append(data_spikes[i][j][k])\n",
    "                    else:\n",
    "                        np.concatenate((encoded_inputs[j][k],encoded_pixels[i][j][k]))\n",
    "            for j in range(len(value_spikes[i])):\n",
    "                    if i==0:\n",
    "                        encoded_outputs[j].append(value_spikes[i][j])\n",
    "                    else:\n",
    "                        np.concatenate((encoded_outputs[j],value_spikes[i][j]))\n",
    "        \n",
    "        return encoded_inputs,encoded_outputs\n",
    "                \n",
    "                    \n",
    "    def __Encode_Digit_Output(self, value, possible_outputs):\n",
    "        output = []\n",
    "        for i in range(len(possible_outputs)):\n",
    "            if value==[possible_outputs]:\n",
    "                spike_train=self.data.Boolean_Encode(1)\n",
    "            else:\n",
    "                spike_train=self.data.Boolean_Encode(0)\n",
    "            output.append(spike_train)\n",
    "        return output\n",
    "                    \n",
    "\n",
    "    def __Decode_Sample(self,encoded_sample,possible_outputs):\n",
    "        spike_counts = []\n",
    "        for i in range(len(encoded_sample)):\n",
    "            spike_counts.append(np.sum(encoded_sample[i]))\n",
    "        output_index=np.argmax(spike_counts)\n",
    "        return possible_outputs[output_index]\n",
    "                   \n",
    "    def Parse_Digit_Dataset(self,option):\n",
    "        data,values,possible_outputs=self.__Obtain_MNIST_Data(option)\n",
    "        (train_data,train_values), (test_data,test_values), (validation_data,validation_values) = self.__Train_Test_Split(data,values)\n",
    "\n",
    "        encoded_train_data,encoded_train_output=self.__Concatenate_For_Training(self.__Encode_All_Samples(train_data,train_values,possible_outputs))\n",
    "        encoded_validation_data, encoded_validation_output = self.__Encode_All_Samples(validation_data,validation_values,possible_outputs)\n",
    "        encoded_test_data, encoded_test_output = self.__Encode_All_Samples(test_data,test_values,possible_outputs)\n",
    "        return possible_outputs, (encoded_train_data, encoded_train_output),(encoded_test_data,test_values),(encoded_validation_data,validation_values)\n",
    "                    \n",
    "    \n",
    "    def Decode_Digit_Results(self,encoded_results,possible_outputs):\n",
    "        results = []\n",
    "        for i in range(len(encoded_results)):\n",
    "            test_result=self.__Decode_Sample(encoded_results[i],possible_outputs)\n",
    "            results.append(test_result)\n",
    "        return results\n",
    "                    \n",
    "    def Determine_Accuracy(self,true_values,predicted_values):\n",
    "        return accuracy_score(true_values,predicted_values)\n",
    "        \n",
    "            \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2, 356]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-679-7f90779fc40f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;31m#Run_Testing('AND')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;31m#Run_Testing('OR')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m \u001b[0mRun_Testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-679-7f90779fc40f>\u001b[0m in \u001b[0;36mRun_Testing\u001b[0;34m(option)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mGate_Test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'ALL'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'1-3'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'1-8'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mDigit_Test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;31m#Uncomment as needed for different tests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-679-7f90779fc40f>\u001b[0m in \u001b[0;36mDigit_Test\u001b[0;34m(network, option)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mdigit_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDigit_Data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mpossible_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mencoded_train_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoded_train_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_test_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_validation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_values\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdigit_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParse_Digit_Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset Spikes Established\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-678-049d906779c8>\u001b[0m in \u001b[0;36mParse_Digit_Dataset\u001b[0;34m(self, option)\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mParse_Digit_Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpossible_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__Obtain_MNIST_Data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_values\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__Train_Test_Split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mencoded_train_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoded_train_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__Concatenate_For_Training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__Encode_All_Samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpossible_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-678-049d906779c8>\u001b[0m in \u001b[0;36m__Train_Test_Split\u001b[0;34m(self, data, values)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__Train_Test_Split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_values\u001b[0m \u001b[0;34m=\u001b[0m                         \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_ratio\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_ratio\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2029\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2031\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2033\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 204\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2, 356]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def Gate_Test(network,option):\n",
    "    dt=1\n",
    "    nbins=1000\n",
    "    data=Data(dt,nbins)\n",
    "\n",
    "    n_tests=100\n",
    "    x,y,z=data.Generate_Gate_Data(option,n_tests)\n",
    "    print(\"Dataset Spikes Established\")\n",
    "    \n",
    "    network.Establish_Network(2)\n",
    "    network.Add_New_Layer(1)\n",
    "    \n",
    "    network.Train([x,y],[z])\n",
    "    print(\"Training Complete\")\n",
    "\n",
    "    (x_1_1,y_1_1),(x_1_0,y_1_0),(x_0_1,y_0_1),(x_0_0,y_0_0)=data.Generate_Gate_Test_Data()\n",
    "    #x_1_1=[data.Encode(1),data.Encode(1)]\n",
    "    #x_1_0=[data.Encode(1),data.Encode(0)]\n",
    "    #x_0_1=[data.Encode(0),data.Encode(1)]\n",
    "    #x_0_0=[data.Encode(0),data.Encode(0)]\n",
    "\n",
    "    plotter=Spike_Plotter()\n",
    "    \n",
    "    z_1_1=network.Test([x_1_1,y_1_1])\n",
    "    title = (str(option)+\" Gate x=1,y=1\")\n",
    "    print(np.sum(x_1_1))\n",
    "    print(np.sum(y_1_1))\n",
    "    print(np.sum(z_1_1[0]))\n",
    "    plotter.Raster_Plot(title,[x_1_1,y_1_1],z_1_1[0])\n",
    "\n",
    "    z_1_0=network.Test([x_1_0,y_1_0])\n",
    "    title = (str(option)+\" Gate x=1,y=0\")\n",
    "    plotter.Raster_Plot(title,[x_1_0,y_1_0],z_1_0[0])\n",
    "    print(np.sum(x_1_0))\n",
    "    print(np.sum(y_1_0))\n",
    "    print(np.sum(z_1_0[0]))\n",
    "    \n",
    "    \n",
    "    z_0_1=network.Test([x_0_1,y_0_1])\n",
    "    title = (str(option)+\" Gate x=0,y=1\")\n",
    "    plotter.Raster_Plot(title,[x_0_1,y_0_1],z_0_1[0])\n",
    "    print(np.sum(x_0_1))\n",
    "    print(np.sum(y_0_1))\n",
    "    print(np.sum(z_0_1[0]))\n",
    "    \n",
    "    z_0_0=network.Test([x_0_0,y_0_0])\n",
    "    title = (str(option)+\" Gate x=0,y=0\")\n",
    "    plotter.Raster_Plot(title,[x_0_0,y_0_0],z_0_0[0])\n",
    "    print(np.sum(x_0_0))\n",
    "    print(np.sum(y_0_0))\n",
    "    print(np.sum(z_0_0[0]))\n",
    "\n",
    "def Digit_Test(network, option):\n",
    "    dt=1\n",
    "    nbins = 1000\n",
    "    digit_data = Digit_Data(dt,nbins)\n",
    "    \n",
    "    possible_outputs, (encoded_train_data,encoded_train_output),(encoded_test_data,test_values),(encoded_validation_data,validation_values) = digit_data.Parse_Digit_Dataset(option)\n",
    "    print(\"Dataset Spikes Established\")\n",
    "    \n",
    "    network.Establish_Network(64)\n",
    "    network.Add_New_Layer(len(possible_outputs))\n",
    "    \n",
    "    number_of_training_iterations=10\n",
    "    validation_spikes = network.Validation_Train(number_of_training_iterations,encoded_train_data,encoded_train_output,encoded_validation_data)\n",
    "    print(\"Training and Validation Complete\")\n",
    "    \n",
    "    test_spikes = network.Test(encoded_test_data)\n",
    "    print(\"Testing Complete\")\n",
    "    \n",
    "    validation_accuracies = []\n",
    "    for i in range(len(validation_spikes)):\n",
    "        validation_predictions=digit_data.Decode_Digit_Results(validation_spikes[i],possible_outputs)\n",
    "        validation_accuracy.append(digit_data.Determine_Accuracy(validation_values,validation_predictions))\n",
    "    \n",
    "    digit_data.Decode_Digit_Results(test_spikes,possible_outputs)\n",
    "    test_accuracy=digit_data.Determine_Accuracy(validation_values,validation_predictions)\n",
    "    \n",
    "    plotter=Spike_Plotter()\n",
    "    plotter.Validation_Plot(self, validations_accuracies)\n",
    "    print(\"For dataset option=\"+str(option)+\", testing accuracy is \"+str(test_accuracy))\n",
    "    \n",
    "def Run_Testing(option):\n",
    "    learning_rate=0.01\n",
    "    minimum_potential=-0.3\n",
    "    threshold_potential=1\n",
    "    resting_potential=0\n",
    "    delay=0.01\n",
    "    A_minus=0.3\n",
    "    A_plus=.8\n",
    "    tau_minus=5\n",
    "    tau_plus=8\n",
    "    w_max=1\n",
    "    w_min=-1\n",
    "\n",
    "    network=Spiking_Neural_Network_Manager()\n",
    "    network.Establish_Parameters(learning_rate,minimum_potential,threshold_potential,resting_potential,delay,A_minus,A_plus,tau_minus,tau_plus,w_max,w_min)\n",
    "    if option=='AND' or option=='OR' or option=='XOR':\n",
    "        Gate_Test(network,option)\n",
    "    elif option=='ALL' or option=='1-3' or option=='1-8':\n",
    "        Digit_Test(network,option)\n",
    "\n",
    "#Uncomment as needed for different tests\n",
    "#Run_Testing('AND')    \n",
    "#Run_Testing('OR')\n",
    "Run_Testing(\"1-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
