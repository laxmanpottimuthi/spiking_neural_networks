{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.datasets import load_digits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class plots the relevant raster plot of spikes and validation accuracy over time\n",
    "\n",
    "class Spike_Plotter:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "     \n",
    "    # Raster plot of spiking behavior for input and output neurons\n",
    "    def Raster_Plot(self,title,input_data,output_data):\n",
    "        \n",
    "        def Convert_Data_To_Raster(data):\n",
    "            result = []\n",
    "            for i in range(len(data)):\n",
    "                result.append([])\n",
    "                for j in range(len(data[i])):\n",
    "                    result[i].append(data[i][j]*j)\n",
    "            return result\n",
    "        \n",
    "        # Set different colors for each neuron\n",
    "        colorCodes = np.array([[0, 0, 0], [1, 0, 0], [0, 1, 0]])\n",
    "\n",
    "        # Set spike colors for each neuron\n",
    "        lineSize = [0.5, 0.5, 0.5]                                  \n",
    "\n",
    "        # Draw a spike raster plot\n",
    "        preparedData = input_data\n",
    "        preparedData.append(np.array(output_data))\n",
    "        neuralData = Convert_Data_To_Raster(preparedData)\n",
    "        \n",
    "        plt.yticks([0,1,2],['Input 1','Input 2','Output'])\n",
    "        plt.eventplot(neuralData, color=colorCodes, linelengths=lineSize)     \n",
    "\n",
    "        plt.title('Spike raster plot')\n",
    "        plt.ylabel('Neuron')\n",
    "        plt.xlabel('Time (msecs)')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    # Plots validation accuracy over time\n",
    "    def Validation_Plot(self, accuracies):\n",
    "        plt.title('Validation Data Accuracy Per Training Iteration')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Training Iteration')\n",
    "        plt.plot(range(len(accuracies)), accuracies)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Neuron Class manages all the parameters and models that are used for testing.  \n",
    "# The class requires the models are first initialized by giving the model parameters before running\n",
    "# Then the proper model's membrane potential function can be called for a given input current\n",
    "# The returned voltage and spiking behavior across the duration of the current will be returned\n",
    "\n",
    "#POTENTIAL_DECAY = 0.8\n",
    "#CURRENT_DECAY = 0.8\n",
    "\n",
    "#class Neuron:\n",
    "#    def __init__(self):\n",
    "#        self.LIF_initialilzed = False\n",
    "\n",
    "#    def Initialize_LIF(self,neuron_resting_voltage,neuron_firing_threshold,C_m, R_m):\n",
    "#        self.C_m = C_m\n",
    "#        self.R_m = R_m\n",
    "#        self.resting_voltage=neuron_resting_voltage\n",
    "#        self.voltage_threshold=neuron_firing_threshold\n",
    "#        self.LIF_initialized = True\n",
    "        \n",
    "#    def LIF_Neuron_Voltage_Current_Change(self,t,I, V_m, spike_trains, trained_weights,spike_occurrence_array):\n",
    "#        if self.LIF_initialized:\n",
    "#            I[t] = CURRENT_DECAY*I[t-1] + np.sum(spike_trains[:,t]*trained_weights)\n",
    "#            if V_m[t-1] < self.voltage_threshold:\n",
    "#                V_m[t] = POTENTIAL_DECAY*V_m[t-1] + I[t]\n",
    "#                spike_occurrence_array[t-1] = 0\n",
    "#            else:\n",
    "#                V_m[t] = self.resting_voltage\n",
    "#                spike_occurrence_array[t-1] = 1\n",
    "#\n",
    "#            return I, V_m\n",
    "#        else:\n",
    "#            raise Exception('LIF was not initialized')\n",
    "#        \n",
    "#    def LIF_Membrane_Potential(self,time, spike_trains, trained_weights):\n",
    "#\n",
    "#        spike_occurrence_array = np.zeros(time)\n",
    "#        current_voltage = self.resting_voltage\n",
    "#        V_m = np.zeros(time)\n",
    "#        input_current = np.zeros(time)\n",
    "#        for t in range(1,time):\n",
    "#            input_current,V_m = self.LIF_Neuron_Voltage_Current_Change(t,input_current, \\\n",
    "#                                       V_m,spike_trains, trained_weights,spike_occurrence_array)\n",
    "#\n",
    "#        return input_current, V_m,spike_occurrence_array\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simplified Leaky-Integrate-And-Fire Neuron designed for STDP\n",
    "# Each neuron keeps track of the parameters used in the SNN construction so that they can be referred to\n",
    "# The neuron tracks each of its fired spikes and the time between firings.\n",
    "# The neuron also holds references to its presynaptic neurons and the weights of those connections\n",
    "\n",
    "class Simplified_Neuron:\n",
    "    def __init__(self,layer_number,parameters):\n",
    "        self.parameters = parameters\n",
    "        self.layer_number=layer_number\n",
    "        \n",
    "        self.t = 0\n",
    "        self.spike_fired=[]\n",
    "        self.time_since_spike=[0]\n",
    "        \n",
    "        self.preset_spikes = False\n",
    "        \n",
    "        self.current_potential = self.parameters.resting_potential\n",
    "        self.presynaptic_neurons = None\n",
    "        self.weights = None\n",
    "        \n",
    "    # Updates the membrane potential of the neuron at each time step based on the incoming spikes of the presynaptic neurons\n",
    "\n",
    "    def Update_Membrane_Potential(self):\n",
    "        if not self.preset_spikes:\n",
    "            spike_fired=0\n",
    "            print(self.t)\n",
    "            if self.t==0:\n",
    "                time_since_spike=1\n",
    "            else:\n",
    "                time_since_spike=self.time_since_spike[self.t]+1\n",
    "            new_potential = self.parameters.resting_potential\n",
    "            if self.parameters.minimum_potential<self.current_potential and self.current_potential < self.parameters.threshold_potential:\n",
    "                incoming_spikes = self.Check_Presynaptic_Spikes()\n",
    "                new_potential = self.current_potential+np.sum(incoming_spikes*self.weights)-self.parameters.delay\n",
    "            elif self.parameters.threshold_potential <= self.current_potential:\n",
    "                spike_fired=1\n",
    "                time_since_spike=0\n",
    "                new_potential = self.parameters.resting_potential\n",
    "            elif self.current_potential <= self.parameters.minimum_potential:\n",
    "                new_potential = self.parameters.resting_potential\n",
    "            \n",
    "            self.current_potential = new_potential\n",
    "            self.spike_fired.append(spike_fired)\n",
    "            self.time_since_spike.append(time_since_spike)\n",
    "        self.t+=1\n",
    "    \n",
    "    # Obtains the calculations for updating the weights and updates all the weights to the presynaptic neurons\n",
    "    \n",
    "    #def Update_Weights(self):\n",
    "    #    for i in range(len(self.presynaptic_neurons)):\n",
    "    #        new_weight=self.New_Weight(self.presynaptic_neurons[i],self.weights[i])\n",
    "    #        self.weights[i]=new_weight\n",
    "    \n",
    "    # Sets a series of preset input spikes to represent training data\n",
    "    \n",
    "    def Input_Spikes(self,spike_train):\n",
    "        self.spike_fired = spike_train\n",
    "        time_since_spike_array = []\n",
    "        if spike_train[0]==1:\n",
    "            time_since_spike_array.append(0)\n",
    "        else:\n",
    "            time_since_spike_array.append(1)\n",
    "            \n",
    "        for i in range(1,len(spike_train)):\n",
    "            if spike_train[i]==1:\n",
    "                time_since_spike_array.append(0)\n",
    "            else:\n",
    "                time_since_spike_array.append(time_since_spike_array[i-1]+1)\n",
    "        self.time_since_spike = time_since_spike_array\n",
    "        self.preset_spikes = True\n",
    "        \n",
    "    # Resets the membrane potential of the neuron\n",
    "        \n",
    "    def Reset(self):\n",
    "        self.t = 0\n",
    "        \n",
    "    # Resets the neuron to default after using the training spike information\n",
    "    def Complete_Training(self):\n",
    "        self.Reset()\n",
    "        self.spike_fired = []\n",
    "        self.time_since_spike = []\n",
    "        self.current_potential = self.parameters.resting_potential\n",
    "        self.preset_spikes = False\n",
    "    \n",
    "    # Determines if the presynaptic neurons have spiked\n",
    "    def Check_Presynaptic_Spikes(self):\n",
    "        spikes = []\n",
    "        for neuron in self.presynaptic_neurons:\n",
    "            spikes.append(neuron.Check_If_Spike_Fired())\n",
    "        return np.array(spikes)\n",
    "    \n",
    "    # Returns if the array of all neuron spikes up to the current moment\n",
    "    def Get_Spikes(self):\n",
    "        return self.spike_fired\n",
    "    \n",
    "    # Checks if the neuron has spiked at the current time\n",
    "    def Check_If_Spike_Fired(self):\n",
    "        try:\n",
    "            if self.t==0:\n",
    "                return self.spike_fired[0]\n",
    "            else:\n",
    "                return self.spike_fired[self.t-1]\n",
    "        except:\n",
    "            print(\"Error is at iteration \"+str(self.t))\n",
    "    \n",
    "    # Checks how long it has been since the neuron has spiked\n",
    "    def Get_Time_Since_Spike(self):\n",
    "        if self.t==0:\n",
    "            return self.time_since_spike[0]\n",
    "        else:\n",
    "            return self.time_since_spike[self.t-1]\n",
    "    \n",
    "    # Updates the references to all the presynaptic layer neurons and generates initial weights\n",
    "    def Set_Presynaptic_Neurons(self,presynaptic_neurons):\n",
    "        self.presynaptic_neurons = presynaptic_neurons\n",
    "        weights = []\n",
    "        \n",
    "        initial_weights=np.random.uniform(self.parameters.w_min,self.parameters.w_max,len(presynaptic_neurons))\n",
    "        for i in range(len(presynaptic_neurons)):\n",
    "            #weights.append(initial_weights[i])\n",
    "            weights.append(0.5)\n",
    "        self.weights = np.array(weights)\n",
    "    \n",
    "    # Recursive propagation through the layers of the network updating the weights\n",
    "    def Recursive_Weight_Updates(self):\n",
    "        if self.presynaptic_neurons is not None:\n",
    "            for i in range(len(self.presynaptic_neurons)):\n",
    "                neuron = self.presynaptic_neurons[i]\n",
    "                neuron.Recursive_Weight_Updates()\n",
    "                self.weights[i]=self.New_Weight(neuron,self.weights[i])\n",
    "            print(self.weights)\n",
    "    \n",
    "    # Recursive propagation through the layers of the network updating each neurons spiking potential\n",
    "    def Recursive_Spike_Propagation(self):\n",
    "        if self.presynaptic_neurons is not None:\n",
    "            for i in range(len(self.presynaptic_neurons)):\n",
    "                neuron = self.presynaptic_neurons[i]\n",
    "                neuron.Recursive_Spike_Propagation()\n",
    "        self.Update_Membrane_Potential()\n",
    "        \n",
    "    # Gets the time difference between the latest post-synaptic and pre-synaptic spike\n",
    "    def Get_Delta_T(self,presynaptic_neuron):\n",
    "        presynaptic_spike=presynaptic_neuron.Check_If_Spike_Fired()\n",
    "        presynaptic_t = presynaptic_neuron.Get_Time_Since_Spike()\n",
    "        if presynaptic_spike==1 or self.spike_fired[self.t-1]==1:\n",
    "            delta_t=presynaptic_t - self.time_since_spike[self.t-1]\n",
    "        else:\n",
    "            delta_t=0\n",
    "        return delta_t\n",
    "        \n",
    "    # Determines the change in the weight based on the time difference between spikes\n",
    "    def Get_Delta_Weight(self,presynaptic_neuron):\n",
    "        delta_t=self.Get_Delta_T(presynaptic_neuron)\n",
    "        delta_weight=0\n",
    "        if delta_t<=-2:\n",
    "            delta_weight=self.parameters.A_minus*np.exp(delta_t/self.parameters.tau_minus)\n",
    "        elif delta_t>=2:\n",
    "            delta_weight=self.parameters.A_plus*np.exp(delta_t/self.parameters.tau_plus)\n",
    "        print(delta_weight)\n",
    "        return delta_weight\n",
    "    \n",
    "    # Determines the new weight value of each synaptic connection\n",
    "    def New_Weight(self,presynaptic_neuron,old_weight):\n",
    "        delta_weight=self.Get_Delta_Weight(presynaptic_neuron)\n",
    "        new_weight=old_weight\n",
    "        if delta_weight>0:\n",
    "            new_weight = old_weight + self.parameters.learning_rate*delta_weight*(self.parameters.w_max-old_weight)\n",
    "        elif delta_weight<=0:\n",
    "            new_weight = old_weight + self.parameters.learning_rate*delta_weight*(old_weight-self.parameters.w_min)\n",
    "        if new_weight>self.parameters.w_max:\n",
    "            new_weight=self.parameters.w_max\n",
    "        if new_weight<self.parameters.w_min:\n",
    "            new_weight=self.parameters.w_min\n",
    "        return new_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class holds onto all the relevant parameter information of the Spiking Neural Network\n",
    "# so that it can be referenced by other classes\n",
    "\n",
    "class Network_Parameters:\n",
    "     def __init__(self,learning_rate,minimum_potential,threshold_potential,resting_potential,delay,A_minus,A_plus,tau_minus,tau_plus,w_max,w_min):\n",
    "        self.threshold_potential = threshold_potential\n",
    "        self.resting_potential = resting_potential\n",
    "        self.minimum_potential = minimum_potential\n",
    "        self.delay = delay\n",
    "        self.learning_rate = learning_rate\n",
    "        self.A_minus=A_minus\n",
    "        self.A_plus=A_plus\n",
    "        self.tau_minus=tau_minus\n",
    "        self.tau_plus=tau_plus\n",
    "        self.w_max = w_max\n",
    "        self.w_min = w_min\n",
    "\n",
    "# The STDP Spiking Neural Network that holds the neuron layers\n",
    "# The class initiates updates to weights and membrane potentials\n",
    "\n",
    "class Spiking_Neural_Network:\n",
    "    def __init__(self,num_of_input_neurons,parameters):\n",
    "        self.parameters=parameters\n",
    "        self.input_neurons = []\n",
    "        self.output_neurons = []\n",
    "        for i in range(num_of_input_neurons):\n",
    "            neuron=Simplified_Neuron(1,self.parameters)\n",
    "            self.input_neurons.append(neuron)\n",
    "            self.output_neurons.append(neuron)\n",
    "        self.num_of_layers = 1\n",
    "        \n",
    "    # Adds a new layer of neurons to the network and makes that layer the new output layer\n",
    "    def Add_New_Layer(self,num_of_neurons):\n",
    "        self.num_of_layers+=1\n",
    "        new_output_neurons = []\n",
    "        for i in range(num_of_neurons):\n",
    "            neuron=Simplified_Neuron(self.num_of_layers,self.parameters)\n",
    "            neuron.Set_Presynaptic_Neurons(self.output_neurons)\n",
    "            new_output_neurons.append(neuron)\n",
    "        self.output_neurons=new_output_neurons\n",
    "        \n",
    "    # Recursively moves through the layers updating all the weights\n",
    "    def Update_Network_Weights(self):\n",
    "        for neuron in self.output_neurons:\n",
    "            neuron.Recursive_Weight_Updates()\n",
    "            \n",
    "    # Recursively moves through the layers updating all the spiking potentials\n",
    "    def Update_Membrane_Potential(self):\n",
    "        for neuron in self.output_neurons:\n",
    "            neuron.Recursive_Spike_Propagation()\n",
    "            \n",
    "# A network manager that holds onto the SNN as well as it's relevant parameters\n",
    "# Manages the training and testing of the network itself\n",
    "\n",
    "class Spiking_Neural_Network_Manager:\n",
    "    def __init__(self):\n",
    "        self.parameters_established = False\n",
    "        self.network_established = False\n",
    "    \n",
    "    def Establish_Parameters(self,learning_rate,minimum_potential,threshold_potential,resting_potential,delay,A_minus,A_plus,tau_minus,tau_plus,w_max,w_min):\n",
    "        self.parameters = Network_Parameters(learning_rate,minimum_potential,threshold_potential,resting_potential,delay,A_minus,A_plus,tau_minus,tau_plus,w_max,w_min)\n",
    "        self.parameters_established = True\n",
    "        \n",
    "    def Establish_Network(self,num_of_inputs):\n",
    "        if self.parameters_established:\n",
    "            self.network=Spiking_Neural_Network(num_of_inputs,self.parameters)\n",
    "            self.network_established = True\n",
    "            \n",
    "    def Add_New_Layer(self,num_of_neurons):\n",
    "        if self.network_established:\n",
    "            self.network.Add_New_Layer(num_of_neurons)\n",
    "            \n",
    "    # Sets all the input and output neurons to use preset input spikes for training\n",
    "    def Prepare_To_Train(self,x,y):\n",
    "        for i in range(len(self.network.input_neurons)):\n",
    "            self.network.input_neurons[i].Input_Spikes(x[i])\n",
    "            #print(self.network.input_neurons[i].spike_fired)\n",
    "        for i in range(len(self.network.output_neurons)):\n",
    "            self.network.output_neurons[i].Input_Spikes(y[i])\n",
    "            \n",
    "    # Resets the neurons to initial time state\n",
    "    def Reset(self):\n",
    "        for neuron in self.network.input_neurons:\n",
    "            neuron.Reset()\n",
    "        for neuron in self.network.output_neurons:\n",
    "            neuron.Reset()\n",
    "        \n",
    "    # Completely resets the neuron to default\n",
    "    def Complete_Training(self):\n",
    "        for neuron in self.network.input_neurons:\n",
    "            neuron.Complete_Training()\n",
    "        for neuron in self.network.output_neurons:\n",
    "            neuron.Complete_Training()\n",
    "    \n",
    "    # Sets all the input neurons to use preset input spikes for testing\n",
    "    def Prepare_To_Test(self,x):\n",
    "        for i in range(len(self.network.input_neurons)):\n",
    "            self.network.input_neurons[i].Input_Spikes(x[i])\n",
    "    \n",
    "    # Trains the network using the preset input data x and output data y\n",
    "    def Train(self,x,y):\n",
    "        if self.network_established:\n",
    "            self.Prepare_To_Train(x,y)\n",
    "            \n",
    "            for j in range(100):\n",
    "                for i in range(len(x[0])):\n",
    "                    self.network.Update_Membrane_Potential()\n",
    "                    self.network.Update_Network_Weights()\n",
    "                self.Reset()\n",
    "            self.Complete_Training()\n",
    "            print(self.network.output_neurons[0].weights)\n",
    "    \n",
    "    # Trains the network using the preset input data x and output data y\n",
    "    # After each training iteration, tests the network on the validation data and records the accuracy\n",
    "    \n",
    "    def Validation_Train(self,x,y,validation_x,validation_y):\n",
    "        if self.network_established:\n",
    "            self.Prepare_To_Train(x,y)\n",
    "            \n",
    "            validation_accuracy = []\n",
    "            \n",
    "            for j in range(1):\n",
    "                for i in range(len(x[0])):\n",
    "                    self.network.Update_Membrane_Potential()\n",
    "                    self.network.Update_Network_Weights()\n",
    "                self.Complete_Training()\n",
    "                result=self.Test(validation_x,validation_y)\n",
    "                validation_accuracy.append(result)\n",
    "                \n",
    "            return validation_accuracy\n",
    "                \n",
    "    # Tests the network on the preset input data x and records the output\n",
    "    def Test(self,x):\n",
    "\n",
    "        if self.network_established:\n",
    "            self.Prepare_To_Test(x)\n",
    "            \n",
    "            for i in range(len(x[0])):\n",
    "                self.network.Update_Membrane_Potential()\n",
    "            \n",
    "            result=[]\n",
    "            for neuron in self.network.output_neurons:\n",
    "                result.append(neuron.Get_Spikes())\n",
    "            self.Reset()\n",
    "                \n",
    "            return result\n",
    "                \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manages the encoding and decoding of the data into spike trains that can be input into the network\n",
    "# Records a goal spiking rate per second and how many milliseconds to generate data for\n",
    "class Data:\n",
    "    def __init__(self, spikes_per_second,T):\n",
    "        self.spikes_rate=spikes_per_second\n",
    "        self.T=T\n",
    "\n",
    "    \n",
    "    # Generate Spike Train From a given binary value\n",
    "    def Encode(self,data_value):\n",
    "        if data_value==1:\n",
    "            multiplier=3\n",
    "        elif data_value==0:\n",
    "            multiplier=1\n",
    "        rate = float(multiplier*self.spikes_rate) / self.T\n",
    "        spike_trains=np.random.binomial(size=self.T,n=1,p=rate)\n",
    "        return spike_trains\n",
    "    \n",
    "    # Decodes the binary value from a given spike train\n",
    "    def Decode(self,spike_train):\n",
    "        spike_count = np.sum(spike_train)\n",
    "        spike_rate = float(spike_count)/self.T\n",
    "        value = float(spike_rate) * self.spikes_rate\n",
    "        return spike_count\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Generates spike trains for boolean logic gate inputs 1-1,1-0,0-1,0-0\n",
    "    def gate_input_values(self):\n",
    "        x1 = np.concatenate((self.Encode(1),self.Encode(1),self.Encode(0),self.Encode(0)))\n",
    "        x2 = np.concatenate((self.Encode(1),self.Encode(0),self.Encode(1),self.Encode(0)))\n",
    "        \n",
    "        x=[x1,x2]\n",
    "        return x\n",
    "        \n",
    "    def simple_and_gate(self):\n",
    "        x1 = self.Encode(1)\n",
    "        x2 = self.Encode(0)\n",
    "        y = self.Encode(0)\n",
    "        x=[x1,x2]\n",
    "        return x,y\n",
    "        \n",
    "    # Generates the spike trains of input and output of a boolean 'AND' gate\n",
    "    def and_gate(self):\n",
    "        x = self.gate_input_values()\n",
    "        y = [np.concatenate((self.Encode(1),self.Encode(0),self.Encode(0),self.Encode(0)))]\n",
    "        return x,y\n",
    "        \n",
    "    # Generates the spike trains of input and output of a boolean 'OR' gate\n",
    "    def or_gate(self,spike_trains):\n",
    "        x = self.gate_input_values()\n",
    "        y = [np.concatenate((self.Encode(1),self.Encode(1),self.Encode(1),self.Encode(0)))]\n",
    "        return x,y\n",
    "\n",
    "    # Generates the spike trains of input and output of a boolean 'XOR' gate\n",
    "    def xor_gate(self,spike_trains):\n",
    "        x = self.gate_input_values()\n",
    "        y = [np.concatenate((self.Encode(0),self.Encode(1),self.Encode(1),self.Encode(0)))]\n",
    "        return x,y\n",
    "\n",
    "    # Switch for determining which data to generate\n",
    "    def Generate_Data(self,gate):\n",
    "        if gate=='AND':\n",
    "            x,y=self.and_gate()\n",
    "        elif gate=='OR':\n",
    "            x,y=self.or_gate()\n",
    "        elif gate=='XOR':\n",
    "            x,y=self.xor_gate()\n",
    "        elif gate=='SIMPLE':\n",
    "            x,y=self.simple_and_gate()\n",
    "        return x,y\n",
    "\n",
    "# Generates the digit class data\n",
    "class Digit_Data:\n",
    "    def __init__(self,spikes_per_second,T):\n",
    "        self.train_ratio = 0.75\n",
    "        self.validation_ratio = 0.15\n",
    "        self.test_ratio = 0.10\n",
    "        self.threshold_intensity = 0.035\n",
    "        self.spikes_rate=spikes_per_second\n",
    "        self.T=T\n",
    "        self.output_intensity = 1\n",
    "    \n",
    "    # Obtains the dataset and splits into train, validation and test sets\n",
    "    def generate_data(self):\n",
    "        digits,values  = load_digits()['images'],load_digits()['target']\n",
    "        train_data,test_data,train_values,test_values = train_test_split(digits,values,test_size=1-self.train_ratio)\n",
    "        test_data,validation_data,test_values,validation_values = \\\n",
    "                        train_test_split(test_data,test_values, test_size = self.test_ratio/(self.test_ratio+self.validation_ratio))\n",
    "        return (train_data,train_values), (test_data,test_values), (validation_data,validation_values)\n",
    "    \n",
    "    # Converts to spike trains\n",
    "    def get_spike_train(self,data_value):\n",
    "        if data_value==1:\n",
    "            multiplier=3\n",
    "        elif data_value==0:\n",
    "            multiplier=1\n",
    "        rate = float(multiplier*self.spikes_rate) / self.T\n",
    "        spike_trains=np.random.binomial(size=self.T,n=1,p=rate)\n",
    "        return spike_trains\n",
    "    \n",
    "    # Decods the spike trains\n",
    "    def Decode(self,spike_train):\n",
    "        spike_count = np.sum(spike_train)\n",
    "        spike_rate = float(spike_count)/self.T\n",
    "        value = float(spike_rate) * self.spikes_rate\n",
    "        return spike_count\n",
    "    \n",
    "    # Encodes each pixel into a spike train by determining if the pixel passes a given threshold intensity\n",
    "    def encode(self,data,output):\n",
    "        data = np.concatenate(data).ravel()\n",
    "        data = data / np.sum(data)\n",
    "\n",
    "        for j in range(len(data)):\n",
    "            if data[j] >= self.threshold_intensity:\n",
    "                data[j] = 1\n",
    "            else:\n",
    "                data[j] = 0\n",
    "        new_data = []\n",
    "        for j in range(len(data)):\n",
    "            new_data.append(self.get_spike_train(data[j]))\n",
    "        y = []\n",
    "        for i in range(10):\n",
    "            if i == output:\n",
    "                y.append(self.get_spike_train(1))\n",
    "            else:\n",
    "                y.append(self.get_spike_train(0))\n",
    "        \n",
    "        return np.asarray(new_data), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def Gate_Test():\n",
    "    learning_rate=0.0001\n",
    "    minimum_potential=-0.3\n",
    "    threshold_potential=10\n",
    "    resting_potential=0\n",
    "    delay=0\n",
    "    A_minus=0.3\n",
    "    A_plus=0.8\n",
    "    tau_minus=5\n",
    "    tau_plus=8\n",
    "    w_max=0\n",
    "    w_min=1\n",
    "\n",
    "    plotter=Spike_Plotter()\n",
    "\n",
    "    spikes_per_second=10\n",
    "    T=1000\n",
    "    data=Data(spikes_per_second,T)\n",
    "    print(\"Data Established\")\n",
    "\n",
    "    network=Spiking_Neural_Network_Manager()\n",
    "    network.Establish_Parameters(learning_rate,minimum_potential,threshold_potential,resting_potential,delay,A_minus,A_plus,tau_minus,tau_plus,w_max,w_min)\n",
    "    network.Establish_Network(2)\n",
    "    network.Add_New_Layer(1)\n",
    "    print(\"Network Constructed\")\n",
    "\n",
    "    x,y=data.Generate_Data('AND')\n",
    "    network.Train(x,y)\n",
    "    print(\"Training Complete\")\n",
    "\n",
    "    x_1_1=[data.Encode(1),data.Encode(1)]\n",
    "    x_1_0=[data.Encode(1),data.Encode(0)]\n",
    "    x_0_1=[data.Encode(0),data.Encode(1)]\n",
    "    x_0_0=[data.Encode(0),data.Encode(0)]\n",
    "\n",
    "    y_1_1=network.Test(x_1_1)\n",
    "    title = (\"AND Gate x1=1,x2=1\")\n",
    "    print(\"Y's value is \"+str(data.Decode(y_1_1[0])))\n",
    "    plotter.Raster_Plot(title,x_1_1,y_1_1[0])\n",
    "\n",
    "    title = (\"AND Gate x1=1,x2=0\")\n",
    "    y_1_0=network.Test(x_1_0)\n",
    "    print(\"Y's value is \"+str(data.Decode(y_1_0[0])))\n",
    "    plotter.Raster_Plot(title,x_1_0,y_1_0[0])\n",
    "    \n",
    "    title = (\"AND Gate x1=0,x2=1\")\n",
    "    y_0_1=network.Test(x_0_1)\n",
    "    print(\"Y's value is \"+str(data.Decode(y_0_1[0])))\n",
    "    plotter.Raster_Plot(title,x_0_1,y_0_1[0])\n",
    "\n",
    "    title = (\"AND Gate x1=0,x2=0\")\n",
    "    y_0_0=network.Test(x_0_0)\n",
    "    print(\"Y's value is \"+str(data.Decode(y_0_0[0])))\n",
    "    plotter.Raster_Plot(title,x_0_0,y_0_0[0])\n",
    "\n",
    "    \n",
    "def Digit_Test():\n",
    "    spikes_per_second=10\n",
    "    T=1000\n",
    "    digit_data = Digit_Data(spikes_per_second,T)\n",
    "    (train_data,train_values),(test_data,test_values),(validation_data,validation_values) = digit_data.generate_data()\n",
    "    for i in range(len(train_data)):\n",
    "        digit_test()\n",
    "        \n",
    "    encoded_train_data = digit_data.encode(train_data,train_values)\n",
    "    print(len(train_values))\n",
    "\n",
    "\n",
    "Gate_Test()\n",
    "#Digit_Test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
