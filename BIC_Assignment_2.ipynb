{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPIKE_PROB = 0.8\n",
    "TRAINING_BIAS = 0.01\n",
    "POTENTIAL_DECAY = 0.75\n",
    "CURRENT_DECAY = 0.5\n",
    "INPUT_VALUES=[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class takes lists of input currents, membrane potentials, and spikes and plots them.\n",
    "\n",
    "class Spike_Plotter:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def Plot_Spiking_Behavior(self,input_current,membrane_potential,spikes,title):\n",
    "        fig,axes = plt.subplots(3,1,sharex=True)\n",
    "        t = np.arange(len(input_current))\n",
    "        self.Plot_Current(axes[0],t,input_current)\n",
    "        self.Plot_Membrane_Potential(axes[1],t,membrane_potential)\n",
    "        self.Plot_Spikes(axes[2],t,spikes)\n",
    "        axes[0].set_title(title)\n",
    "        plt.show()\n",
    "    \n",
    "    def Plot_Current(self,ax,t,input_current):\n",
    "        ax.plot(t,input_current)\n",
    "        ax.set_ylabel(\"I (mV)\")\n",
    "    \n",
    "    def Plot_Membrane_Potential(self,ax,t,membrane_potential):\n",
    "        ax.plot(t,membrane_potential)\n",
    "        ax.set_ylabel(\"V (mV)\")\n",
    "    \n",
    "    def Plot_Spikes(self,ax,t,spikes):\n",
    "        ax.plot(t,spikes)\n",
    "        ax.set_ylabel(\"Spikes\")\n",
    "        ax.set_xlabel(\"Time (ms)\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Neuron Class manages all the parameters and models that are used for testing.  \n",
    "# The class requires the models are first initialized by giving the model parameters before running\n",
    "# Then the proper model's membrane potential function can be called for a given input current\n",
    "# The returned voltage and spiking behavior across the duration of the current will be returned\n",
    "\n",
    "#POTENTIAL_DECAY = 0.8\n",
    "#CURRENT_DECAY = 0.8\n",
    "\n",
    "#class Neuron:\n",
    "#    def __init__(self):\n",
    "#        self.LIF_initialilzed = False\n",
    "\n",
    "#    def Initialize_LIF(self,neuron_resting_voltage,neuron_firing_threshold,C_m, R_m):\n",
    "#        self.C_m = C_m\n",
    "#        self.R_m = R_m\n",
    "#        self.resting_voltage=neuron_resting_voltage\n",
    "#        self.voltage_threshold=neuron_firing_threshold\n",
    "#        self.LIF_initialized = True\n",
    "        \n",
    "#    def LIF_Neuron_Voltage_Current_Change(self,t,I, V_m, spike_trains, trained_weights,spike_occurrence_array):\n",
    "#        if self.LIF_initialized:\n",
    "#            I[t] = CURRENT_DECAY*I[t-1] + np.sum(spike_trains[:,t]*trained_weights)\n",
    "#            if V_m[t-1] < self.voltage_threshold:\n",
    "#                V_m[t] = POTENTIAL_DECAY*V_m[t-1] + I[t]\n",
    "#                spike_occurrence_array[t-1] = 0\n",
    "#            else:\n",
    "#                V_m[t] = self.resting_voltage\n",
    "#                spike_occurrence_array[t-1] = 1\n",
    "#\n",
    "#            return I, V_m\n",
    "#        else:\n",
    "#            raise Exception('LIF was not initialized')\n",
    "#        \n",
    "#    def LIF_Membrane_Potential(self,time, spike_trains, trained_weights):\n",
    "#\n",
    "#        spike_occurrence_array = np.zeros(time)\n",
    "#        current_voltage = self.resting_voltage\n",
    "#        V_m = np.zeros(time)\n",
    "#        input_current = np.zeros(time)\n",
    "#        for t in range(1,time):\n",
    "#            input_current,V_m = self.LIF_Neuron_Voltage_Current_Change(t,input_current, \\\n",
    "#                                       V_m,spike_trains, trained_weights,spike_occurrence_array)\n",
    "#\n",
    "#        return input_current, V_m,spike_occurrence_array\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simplified_Neuron:\n",
    "    def __init__(self,layer_number,parameters):\n",
    "        self.parameters = parameters\n",
    "        self.layer_number=layer_number\n",
    "        \n",
    "        self.spike_fired=0\n",
    "        self.current_potential = resting_potential\n",
    "        self.time_since_spike=0\n",
    "        self.presynaptic_neurons = None\n",
    "        self.weights = None\n",
    "        \n",
    "    def Update_Membrane_Potential(self):\n",
    "        self.spike_fired=0\n",
    "        self.time_since_spike+=1\n",
    "        new_potential = self.parameters.resting_potential\n",
    "        if self.parameters.minimum_potential<self.current_potential and self.current_potential < self.parameters.threshold_potential:\n",
    "            incoming_spikes = self.Check_Presynaptic_Spikes()\n",
    "            new_potential = self.current_potential+np.sum(incoming_spikes*self.weights)-self.parameters.delay\n",
    "        elif self.parameters.threshold_potential <= self.current_potential:\n",
    "            self.spike_fired=1\n",
    "            self.time_since_spike=0\n",
    "            new_potential = self.parameters.resting_potential\n",
    "        elif self.current_potential <= self.parameters.minimum_potential:\n",
    "            new_potential = self.resting_potential\n",
    "        self.current_potential = new_potential\n",
    "    \n",
    "    def Update_Weights(self):\n",
    "        for i in range(len(self.presynaptic_neurons)):\n",
    "            new_weight=self.New_Weight(self.presynaptic_neurons[i],self.weights[i])\n",
    "            self.weights[i]=new_weight\n",
    "    \n",
    "    \n",
    "    def Check_Presynaptic_Spikes(self):\n",
    "        spikes = []\n",
    "        for neuron in self.presynaptic_neurons:\n",
    "            spikes.append(neuron.Check_If_Spike_Fired())\n",
    "        return np.array(spikes)\n",
    "            \n",
    "    def Check_If_Spike_Fired(self):\n",
    "        return self.spike_fired\n",
    "    \n",
    "    def Get_Time_Since_Spike(self):\n",
    "        return self.time_since_spike\n",
    "    \n",
    "    def Set_Presynaptic_Neurons(self,presynaptic_neurons)\n",
    "        self.presynaptic_nerons = presynaptic_neurons\n",
    "        weights = []\n",
    "        for i in range(len(presynaptic_neurons)):\n",
    "            weights.append(0.5)\n",
    "        self.weights = np.array(weights)\n",
    "    \n",
    "    def Recursive_Weight_Updates(self):\n",
    "        if self.presynaptic_neurons not None:\n",
    "            for i in range(len(self.presynaptic_neurons)):\n",
    "                neuron = self.presynaptic_neurons[i]\n",
    "                neuron.Recursive_Weight_Updates()\n",
    "                self.weights[i]=self.New_Weight(neuron,self.weights[i])\n",
    "    \n",
    "    def Recursive_Spike_Propagation(self):\n",
    "        if self.presynaptic_neurons not None:\n",
    "            for i in range(len(self.presynaptic_neurons)):\n",
    "                neuron = self.presynaptic_neurons[i]\n",
    "                neuron.Recursive_Spike_Propagation()\n",
    "                self.Update_Membrane_Potential()\n",
    "        \n",
    "    \n",
    "    def Get_Delta_T(self,presynaptic_neuron):\n",
    "        presynaptic_spike=presynaptic_neuron.Check_If_Spike_Fired()\n",
    "        presynaptic_t = presynaptic_neuron.Get_Time_Since_Spike()\n",
    "        if presynaptic_spike==1 or self.spike_fired==1:\n",
    "            delta_t=presynaptic_t - self.time_since_spike\n",
    "        else:\n",
    "            delta_t=0\n",
    "        return delta_t\n",
    "        \n",
    "    def Get_Delta_Weight(self,presynaptic_neuron):\n",
    "        delta_t=self.Get_Delta_T(presynaptic_neuron)\n",
    "        delta_weight=0\n",
    "        if delta_t<=-2:\n",
    "            delta_weight=self.A_minus*np.exp(delta_t/self.tau_minus)\n",
    "        elif delta_t>=2:\n",
    "            delta_weight=self.A_plus*np.exp(self.delta_t/tau_plus)\n",
    "        return delta_weight\n",
    "    \n",
    "    def New_Weight(self,presynaptic_neuron,old_weight):\n",
    "        delta_weight=Get_Delta_Weight(presynaptic_neuron)\n",
    "        new_weight=old_weight\n",
    "        if delta_weight>0:\n",
    "            new_weight = old_weight + self.parameters.learning_rate*(self.parameters.max_w-old_weight)\n",
    "        elif delta<=0:\n",
    "            new_weight = old_weight + self.parameters.learning_rate*(old_weight-self.parameters.min_w)\n",
    "        return new_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network_Parameters():\n",
    "     def __init__(learning_rate,minimum_potential,threshold_potential,resting_potential,delay,A_minus,A_plus,tau_minus,tau_plus,w_max,w_min):\n",
    "        self.threshold_potential = threshold_potential\n",
    "        self.refractory_potential = refractory_potential\n",
    "        self.resting_potential = resting_potential\n",
    "        self.minimum_potential = minimum_potential\n",
    "        self.delay = delay\n",
    "        self.learning_rate = learning_rate\n",
    "        self.A_minus=A_minus\n",
    "        self.A_plus=A_plus\n",
    "        self.tau_minus=tau_minus\n",
    "        self.tau_plus=tau_plus\n",
    "        self.w_max = w_max\n",
    "        self.w_min = w_min\n",
    "\n",
    "class Spiking_Neural_Network:\n",
    "    def __init__(self,num_of_input_neurons,parameters):\n",
    "        self.parameters=parameters\n",
    "        self.input_neurons = []\n",
    "        self.output_neurons = []\n",
    "        for i in range(num_of_input_neurons):\n",
    "            neuron=Simplified_Neuron(1,self.parameters)\n",
    "            self.input_neurons.append(neuron)\n",
    "            self.output_neurons.append(neuron)\n",
    "        self.num_of_layers = 1\n",
    "        \n",
    "    def Add_New_Layer(self,num_of_neurons):\n",
    "        self.num_of_layers+=1\n",
    "        new_output_neurons = []\n",
    "        for i in range(len(num_of_neurons)):\n",
    "            neuron=Simplified_Neuron(self.num_of_layers,self.parameters)\n",
    "            neuron.Set_Presynaptic_Neurons(self.output_neurons)\n",
    "            new_output_neurons.append(neuron)\n",
    "        self.output_neurons=new_output_neurons\n",
    "        \n",
    "    def Update_Network_Weights(self):\n",
    "        for neuron in self.output_neurons:\n",
    "            neuron.Recursive_Weight_Updates()\n",
    "            \n",
    "    def Update_Membrane_Potential(self):\n",
    "        for neuron in self.output_neurons:\n",
    "            neuron.Recursive_Spike_Propogation()\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, size, num_neurons, gate):\n",
    "        self.spike_train_size = size\n",
    "        self.gate = gate\n",
    "        if len(INPUT_VALUES) == 0 or len(INPUT_VALUES) == 1 or num_neurons == 0 or num_neurons == 1:\n",
    "            raise Exception(\"Input values/number of neurons cannot be 0 or 1\")\n",
    "        elif len(INPUT_VALUES) == num_neurons:\n",
    "            self.num_neurons = num_neurons\n",
    "        else:\n",
    "            raise Exception(\"Input values length and number of neurons should be same\")\n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "    Based on inputs, get spike probabilities\n",
    "    \"\"\"\n",
    "    def get_spike_prob(self,neuron_input):\n",
    "        if neuron_input == 1:\n",
    "            return 1-SPIKE_PROB, SPIKE_PROB\n",
    "        else:\n",
    "            return SPIKE_PROB,1-SPIKE_PROB\n",
    "    \n",
    "    \"\"\"\n",
    "    Usage of AND/OR/XOR operators on multiple spike trains\n",
    "    \"\"\"\n",
    "    def and_gate(self,spike_trains):\n",
    "        result = np.logical_and(spike_trains[0],spike_trains[1])\n",
    "        for i in range(2, len(spike_trains)):\n",
    "            result = np.logical_and(result, spike_trains[i])\n",
    "        return result    \n",
    "    def or_gate(self,spike_trains):\n",
    "        result = np.logical_and(spike_trains[0],spike_trains[1])\n",
    "        for i in range(2, len(spike_trains)):\n",
    "            result = np.logical_or(result, spike_trains[i])\n",
    "        return result\n",
    "    def xor_gate(self,spike_trains):\n",
    "        result = np.logical_and(spike_trains[0],spike_trains[1])\n",
    "        for i in range(2, len(spike_trains)):\n",
    "            result = np.logical_xor(result, spike_trains[i])\n",
    "        return result\n",
    "    \n",
    "    \"\"\"\n",
    "    Generate spike trains\n",
    "    \"\"\"\n",
    "    def encode(self,neurons):\n",
    "        #Need to change this to someother distribution\n",
    "        spike_trains = []\n",
    "        for neuron_value in neurons:\n",
    "            prob_dist = self.get_spike_prob(neuron_value)\n",
    "            spike_trains.append(np.random.choice(INPUT_VALUES, self.spike_train_size,p=prob_dist))\n",
    "        self.spike_trains = np.asarray(spike_trains)\n",
    "        return self.spike_trains\n",
    "    \n",
    "    \"\"\"\n",
    "    Generate teacher neuron based on input gate and spike trains\n",
    "    \"\"\"\n",
    "    def teacher_neuron(self):\n",
    "        spike_trains = self.spike_trains\n",
    "        gate = self.gate\n",
    "        if gate == \"AND\":\n",
    "            self.teacher = self.and_gate(spike_trains)\n",
    "        if gate == \"OR\":\n",
    "            self.teacher = self.or_gate(spike_trains)\n",
    "        if gate == \"XOR\":\n",
    "            self.teacher = self.xor_gate(spike_trains)\n",
    "        return self.teacher.astype(int)\n",
    "    \n",
    "    \"\"\"\n",
    "    Generate input, encoded data of data size - data_size\n",
    "    \"\"\"\n",
    "    def generate_data(self,data_size):\n",
    "        \n",
    "        generated_data = []\n",
    "        neurons_input = [] \n",
    "        for _ in range(self.num_neurons):\n",
    "            neurons_input.append(np.random.choice([0,1],data_size))\n",
    "        neurons_input = np.asarray(neurons_input).T\n",
    "\n",
    "        for each_neuron_set in neurons_input:\n",
    "            generated_data.append((each_neuron_set, self.encode(each_neuron_set), self.teacher_neuron()))\n",
    "            \n",
    "        return generated_data\n",
    "\n",
    "\n",
    "class Train:\n",
    "    def __init__(self,spike_train,teacher):\n",
    "        self.bias = TRAINING_BIAS\n",
    "        self.teacher = teacher\n",
    "        self.spike_trains = spike_train\n",
    "        self.len_spike_train = len(spike_train)\n",
    "        self.weigths = np.random.normal(0,0.1,self.len_spike_train)\n",
    "    \n",
    "    def get_a_corr(self,spike_train, teacher):\n",
    "        #This needs to be changed\n",
    "        return np.logical_and(spike_train,teacher).astype(int)\n",
    "        \n",
    "    \n",
    "    def fit(self):\n",
    "        for i,spike_train in enumerate(self.spike_trains):\n",
    "            for j,(n,t) in enumerate(zip(spike_train,teacher)):\n",
    "                a_corr = self.get_a_corr(spike_train, teacher)\n",
    "\n",
    "                dw = a_corr[j]*n*t - TRAINING_BIAS\n",
    "                self.weigths[i] = abs(self.weigths[i] + dw -1)\n",
    "        return self.weigths\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(teacher,output):\n",
    "    return sum(output)/sum(teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for neurons set:  [1 0] is  3.0\n",
      "Accuracy for neurons set:  [0 1] is  3.0\n",
      "Accuracy for neurons set:  [0 1] is  3.0\n",
      "Accuracy for neurons set:  [1 1] is  0.0\n",
      "Accuracy for neurons set:  [0 1] is  3.0\n"
     ]
    }
   ],
   "source": [
    "#LIP Parameters\n",
    "neuron_resting_voltage=0\n",
    "neuron_firing_threshold=0.5\n",
    "C_m=2\n",
    "R_m=1.5\n",
    "\n",
    "\n",
    "\n",
    "neuron=Neuron()\n",
    "neuron.Initialize_LIF(neuron_resting_voltage,neuron_firing_threshold,C_m,R_m)\n",
    "plotter = Spike_Plotter()\n",
    "\n",
    "\n",
    "time = 20\n",
    "data = Data(time,2,\"AND\")\n",
    "generated_data = data.generate_data(5)\n",
    "\n",
    "\n",
    "for (neuron_input, spike_train, teacher) in generated_data:\n",
    "    train_model = Train(spike_train,teacher)\n",
    "    trained_weights = train_model.fit()\n",
    "    input_current, membrane_potential,spike_occurrence = neuron.LIF_Membrane_Potential(time,spike_train,trained_weights)\n",
    "#     plotter.Plot_Spiking_Behavior(input_current,membrane_potential,spike_occurrence,\"LIF Neuron\")\n",
    "    accuracy = get_accuracy(teacher,spike_occurrence)\n",
    "    print(\"Accuracy for neurons set: \", neuron_input, \"is \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.logical_and(spike_train[0],spike_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(spike_occurrence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97551509, 0.95895063])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Testingbed\n",
    "# data = Data(10,2,\"AND\")\n",
    "# spike_train, teacher = data.generate_data()\n",
    "# # teacher = data.teacher_neuron()\n",
    "\n",
    "# train = Train(spike_train,teacher)\n",
    "# weights = train.fit()\n",
    "# print(spike_train[0])\n",
    "# print(spike_train[1])\n",
    "# print(teacher)\n",
    "# print(weights)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
